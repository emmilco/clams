## BUG-014: Fix extreme memory usage in index_codebase (15GB+)

### Summary
Fixed PyTorch MPS backend memory leak that caused 15+ GB memory usage and severe performance degradation when running `index_codebase` on Apple Silicon Macs.

### Root Cause
The embedding model (`nomic-ai/nomic-embed-text-v1.5`) automatically loaded on Apple's MPS (GPU) device. PyTorch's MPS backend has known memory management issues where GPU memory allocated for tensors during embedding operations is not properly released, causing memory accumulation and 55+ second per-file processing times.

### Changes
- Modified `NomicEmbedding.__init__` to force CPU execution when MPS is available
- Added `torch` import for device detection
- Added 3 comprehensive regression tests to verify the fix

### Files Changed
- `src/learning_memory_server/embedding/nomic.py` - Force CPU to avoid MPS leak
- `tests/embedding/test_bug_014_mps_workaround.py` - Regression tests (new file)
