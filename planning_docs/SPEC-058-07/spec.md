# SPEC-058-07: CALM Cutover - Switch from Old to New System

## Overview

Switch the active system from CLAMS/CLAWS to CALM. This involves migrating existing data, updating configuration to point to the new MCP server and hooks, updating CLAUDE.md to document the new system, and verifying everything works end-to-end.

**Precondition**: CALM is fully implemented (SPEC-058-01 through 058-06 complete). The old CLAMS server and CLAWS bash scripts are still active and in use.

**Postcondition**: CALM is the active system. Old CLAMS/CLAWS still exists in the codebase (removal is SPEC-058-08) but is no longer referenced by any configuration.

## Scope

### In Scope

1. **Data migration script** - One-off script to migrate existing state
2. **Configuration update** - MCP server registration, hook registration
3. **CLAUDE.md update** - Document the new CALM-based workflow
4. **Verification** - Test that migrated data is accessible and all features work

### Out of Scope

- Removing old code (`src/clams/`, `.claude/bin/claws-*`, `clams_scripts/`) - That's SPEC-058-08
- Building `calm migrate` as a permanent CLI feature - This is a one-off operation
- Public distribution or packaging

## Detailed Requirements

### 1. Migration Script (`scripts/cutover.py`)

A one-off Python script that performs the atomic cutover. Must be idempotent (safe to run multiple times).

#### 1.1 Stop Old Server

- Stop the old CLAMS MCP server process (`pkill -f "clams.server"` or equivalent)
- Verify it's stopped
- If it fails to stop, print a warning and continue (it may already be stopped)

#### 1.2 Migrate CLAMS Data (`~/.clams/` → `~/.calm/`)

Source directory: `~/.clams/`
Target directory: `~/.calm/`

**Important context on old CLAMS data storage**: The old CLAMS system stores memories, GHAP entries, and experience embeddings in **Qdrant** (vector database), NOT in SQLite. The `~/.clams/metadata.db` SQLite database only contains code indexing tables (`indexed_files`, `call_graph`, `projects`, `git_index_state`).

**Code indexing tables** from `~/.clams/metadata.db`:
- `indexed_files` → Copy to `~/.calm/metadata.db` `indexed_files` table. Schemas are compatible.
- `projects` → Copy to `~/.calm/metadata.db` `projects` table. Schemas are compatible.
- `git_index_state` → Copy to `~/.calm/metadata.db` `git_index_state` table. Schemas are compatible.
- `call_graph` → **NOT migrated**. This table does not exist in the new CALM schema. Call graph data is regenerated by re-indexing.

**Session journal data** from `~/.clams/journal/`:
- Session entries are stored as JSONL at `~/.clams/journal/session_entries.jsonl` (currently empty).
- Archived entries in `~/.clams/journal/archive/`.
- If either file contains data, parse the JSONL entries and insert into the new `session_journal` table in `~/.calm/metadata.db`. Map JSONL fields to the new table schema.
- If the files are empty or don't exist, skip this step.

**Qdrant vector data**:
- Memories, GHAP entries, code embeddings, and commit embeddings are stored in Qdrant collections.
- These are **NOT migrated** by this script. The new CALM system uses the same Qdrant instance and the same collection names, so these collections will continue to work as-is.
- If the Qdrant collections are incompatible (which they should not be, since CALM was built to reuse them), re-indexing can regenerate them.

**Config**:
- Do NOT migrate `~/.clams/config.yaml` or `~/.clams/config.env` - the new system has its own defaults and the install script handles config creation.

#### 1.3 Migrate CLAWS Data (`.claude/claws.db` → `~/.calm/metadata.db`)

Source: `.claude/claws.db` (orchestration state - tasks, workers, reviews, test runs, counters, sessions)
Target: `~/.calm/metadata.db`

**`tasks` table** - Column mapping:
| Old (claws.db) | New (calm metadata.db) | Notes |
|---|---|---|
| `id` | `id` | Direct copy |
| `spec_id` | `spec_id` | Direct copy |
| `title` | `title` | Direct copy |
| `phase` | `phase` | Direct copy |
| `assigned_specialist` | `specialist` | **Renamed** |
| `worktree_path` | `worktree_path` | Convert relative paths to absolute |
| `created_at` | `created_at` | Direct copy |
| `updated_at` | `updated_at` | Direct copy |
| `blocked_by` | `blocked_by` | Direct copy (JSON array) |
| `notes` | `notes` | Direct copy |
| `task_type` | `task_type` | Direct copy |
| *(not present)* | `project_path` | Set to absolute path of current git repo root |

**`workers` table** - Column mapping:
| Old (claws.db) | New (calm metadata.db) | Notes |
|---|---|---|
| `id` | `id` | Direct copy |
| `specialist_type` | `role` | **Renamed** |
| `current_task_id` | `task_id` | **Renamed** |
| `status` | `status` | Map `'idle'` → `'completed'` (idle workers are effectively done) |
| `started_at` | `started_at` | Direct copy |
| `ended_at` | `ended_at` | Direct copy |
| *(not present)* | `project_path` | Set to absolute path of current git repo root |

**`reviews` table** - Column mapping:
| Old (claws.db) | New (calm metadata.db) | Notes |
|---|---|---|
| `id` | `id` | Direct copy (autoincrement) |
| `task_id` | `task_id` | Direct copy |
| `artifact_type` | `review_type` | **Renamed**. Values are compatible ('spec', 'proposal', 'code') |
| `review_num` | *(dropped)* | Not in new schema |
| `reviewer_worker_id` | `worker_id` | **Renamed** |
| `result` | `result` | Direct copy |
| `issues_found` | `reviewer_notes` | **Renamed** |
| `created_at` | `created_at` | Direct copy |

**`test_runs` table** - Column mapping:
| Old (claws.db) | New (calm metadata.db) | Notes |
|---|---|---|
| `id` | `id` | Direct copy (autoincrement) |
| `task_id` | `task_id` | Direct copy |
| `passed` | `passed` | Direct copy |
| `failed` | `failed` | Direct copy |
| `skipped` | `skipped` | Direct copy |
| `execution_time_seconds` | `duration_seconds` | **Renamed** |
| `failed_tests` | `failed_tests` | Direct copy (JSON array) |
| `run_at` | `run_at` | Direct copy |
| `worktree` | *(dropped)* | Not in new schema |
| `commit_sha` | *(dropped)* | Not in new schema |
| `total_tests` | *(dropped)* | Not in new schema |
| `errors` | *(dropped)* | Not in new schema |
| `test_files` | *(dropped)* | Not in new schema |

**`system_counters` → `counters` table** - Table name change:
| Old (claws.db) | New (calm metadata.db) | Notes |
|---|---|---|
| `name` | `name` | Direct copy |
| `value` | `value` | Use MAX(old, new) if counter exists in both |

Note: The old table is named `system_counters`, the new table is `counters`.

**`phase_transitions` table** - Column mapping:
| Old (claws.db) | New (calm metadata.db) | Notes |
|---|---|---|
| All columns | Same names | Compatible. Old `from_phase` allows NULL; new requires NOT NULL. Set NULL values to empty string `''`. |

**`gate_passes` table** - Schema is identical between old and new. Copy all rows directly.

**`sessions` table** - Schema is compatible between old and new. Copy all rows directly (handoff content, continuation flags).

**Tables intentionally NOT migrated from CLAWS:**
- `merge_log` - Merge history. Not in new schema. Historical data, not needed for operation.
- `violations` - Violation records. Not in new schema. Historical data, not needed for operation.

**Worktree paths:**
- Any `worktree_path` values in the `tasks` table that are relative (e.g., `.worktrees/SPEC-001`) must be converted to absolute paths relative to the git repo root.

#### 1.4 Ensure CALM Infrastructure

Before migration, set up the target:
- Create `~/.calm/` directory structure (`workflows/`, `roles/`, `sessions/`)
- Initialize `~/.calm/metadata.db` with the CALM schema (using `init_database()` from `src/calm/db/schema.py`)
- Copy role files and workflow templates from `src/calm/templates/`
- Ensure Qdrant container is running (check, start if needed)

This should run BEFORE data migration so the target database has the correct schema.

#### 1.5 Register CALM in Configuration

Use the existing `calm install` config merge functionality:

- Register CALM MCP server in `~/.claude.json` (server key: `"calm"`)
- Register CALM hooks in `~/.claude/settings.json`
- Remove old CLAMS hook references from `~/.claude/settings.json` (matching `clams_scripts/hooks/` paths)
- Remove old CLAMS MCP server from `~/.claude.json` (server key: `"clams"`, if present)

#### 1.6 Start CALM Server

- Start the CALM MCP server daemon
- Verify it responds to ping
- If it fails to start, print error and exit with non-zero code

#### 1.7 Verification

After migration, run automated verification:
- Count tasks in old vs new database, print comparison
- Count reviews in old vs new database, print comparison
- Count counter values in old vs new, print comparison
- Count phase transitions in old vs new, print comparison
- Count gate passes in old vs new, print comparison
- Count sessions in old vs new, print comparison
- If any count mismatches, print WARNING (not error - idempotent runs may show differences)
- Print summary: "Migration complete. X tasks, Y reviews, Z counters migrated."

### 2. CLAUDE.md Update

Replace the current CLAUDE.md (which documents `.claude/bin/claws-*` commands) with a new version that:

- Documents the CALM system and how to activate orchestration via `/orchestrate`
- References `calm` CLI commands instead of `claws-*` bash scripts
- Keeps all the workflow documentation (phases, gates, roles, etc.)
- Documents the `/wrapup` and `/reflection` skills
- Removes all references to `.claude/bin/claws-*` scripts
- Updates specialist role file paths (`.claude/roles/` → `~/.calm/roles/`)
- Removes the "Available Tools" section listing bash scripts and replaces with CALM CLI reference
- Updates the session continuity section to use CALM session tools

The CLAUDE.md should clearly indicate that:
- Running `/orchestrate` at session start activates full workflow mode
- Memory features (GHAP, memories, context assembly) are always active
- The `calm` CLI is available for direct command-line operations

### 3. Verification Test Suite

Add integration tests that verify:
- Migration script correctly transfers data between database schemas with proper column mappings
- Column renames are handled correctly (`assigned_specialist` → `specialist`, `artifact_type` → `review_type`, etc.)
- Counter values are preserved (using MAX when both exist)
- Task phase history is maintained, with NULL `from_phase` values defaulted to `''`
- Gate passes are copied correctly
- Sessions (handoff data) are migrated
- Worktree paths are converted from relative to absolute
- Code indexing tables from CLAMS metadata.db are migrated
- Configuration files are updated correctly (MCP server added/removed, hooks added/removed)
- Dry run mode reports counts without modifying anything
- Running the script twice produces the same result (idempotency)

Use temporary directories and mock databases (do not touch real `~/.clams/` or `~/.calm/` in tests).

### 4. Dry Run Mode

The migration script must support `--dry-run` flag that:
- Reports what would be migrated (counts per table from each source database)
- Reports what configuration changes would be made
- Reports column mappings that will be applied
- Does NOT modify any files or databases
- Prints a clear summary

### 5. Backup Before Migration

Before any data modification:
- Create backup of `~/.clams/metadata.db` → `~/.clams/metadata.db.pre-cutover`
- Create backup of `.claude/claws.db` → `.claude/claws.db.pre-cutover`
- Create backup of `~/.claude.json` → `~/.claude.json.pre-cutover`
- Create backup of `~/.claude/settings.json` → `~/.claude/settings.json.pre-cutover`
- If any backup target already exists (from a previous run), skip creating it (preserve the original backup)

## Acceptance Criteria

- [ ] Migration script exists at `scripts/cutover.py`
- [ ] Script migrates code indexing tables (`indexed_files`, `projects`, `git_index_state`) from `~/.clams/metadata.db` to `~/.calm/metadata.db`
- [ ] Script migrates JSONL session entries from `~/.clams/journal/` to `session_journal` table (if any exist)
- [ ] Script migrates all CLAWS orchestration data (tasks, workers, reviews, test runs, counters, phase transitions, gate passes, sessions) from `.claude/claws.db` to `~/.calm/metadata.db` with correct column mappings
- [ ] Script handles column renames: `assigned_specialist`→`specialist`, `specialist_type`→`role`, `current_task_id`→`task_id`, `artifact_type`→`review_type`, `reviewer_worker_id`→`worker_id`, `issues_found`→`reviewer_notes`, `execution_time_seconds`→`duration_seconds`, `system_counters`→`counters`
- [ ] Script converts relative worktree paths to absolute paths
- [ ] Script backs up all source databases and config files before modifying anything (skips if backup already exists)
- [ ] Script supports `--dry-run` flag
- [ ] Script is idempotent (running twice produces the same result)
- [ ] Script removes old CLAMS MCP server (key: `"clams"`) and hooks from configuration
- [ ] Script registers CALM MCP server (key: `"calm"`) and hooks in configuration
- [ ] CLAUDE.md updated to document CALM workflow (no references to `claws-*` scripts)
- [ ] Integration tests verify migration correctness with mock data, covering all column mappings
- [ ] All existing tests continue to pass
- [ ] After running the script, `calm task list` shows migrated tasks
- [ ] After running the script, `calm counter list` shows migrated counter values

## Non-Goals

- Building a reusable migration framework
- Supporting rollback (backups are sufficient)
- Migrating Qdrant vector data (existing collections are reused as-is by the new system)
- Migrating `call_graph` table (regenerated by re-indexing)
- Migrating `merge_log` or `violations` tables (historical data, not in new schema)
- Removing old code (SPEC-058-08)

## Technical Notes

- The `calm install` module (`src/calm/install/`) already has config merge utilities (`register_mcp_server`, `register_hooks`, `_clean_old_hooks`). Reuse these.
- The `init_database()` function from `src/calm/db/schema.py` creates all tables idempotently (uses `CREATE TABLE IF NOT EXISTS`).
- Qdrant vector collections are shared between old and new systems. No migration needed - they'll be accessible to CALM immediately.
- The script should be runnable with `python scripts/cutover.py` (no special dependencies beyond what's already in the project).
- For handling `INSERT OR REPLACE` / `INSERT OR IGNORE` behavior during idempotent runs, use `INSERT OR REPLACE` for most tables to allow re-running the script to update data.
