# BUG-012: index_codebase hangs and doesn't ignore .venv/node_modules

## Reported

- **First noticed on commit**: 372d7535e06753d773c46bb327eddc3ace434017
- **Reported by**: orchestrator
- **Reported at**: 2025-12-07
- **Severity**: high

## Reproduction Steps

1. Call `index_codebase` MCP tool on a directory containing `.venv/` or `node_modules/`
2. Observe that the indexing process hangs indefinitely

**Example call**:
```python
index_codebase(
    directory="/Users/elliotmilco/Documents/GitHub/clams",
    project="clams",
    recursive=True
)
```

**Expected**:
- The indexer should respect `.gitignore` patterns or have sensible defaults to exclude:
  - `.venv/`
  - `node_modules/`
  - `.git/`
  - `__pycache__/`
  - Build artifacts (e.g., `dist/`, `build/`, `target/`)
- Indexing should complete in seconds to minutes for typical projects

**Actual**:
- The indexer attempts to process ALL files including 65,694 files in `.venv/`
- Project has 89,746 total files (2.7GB) but only ~59 actual source files in `src/`
- Indexing hangs indefinitely (tested for 10+ minutes with no completion)
- Even indexing just `src/` (59 Python files) hangs, suggesting a secondary issue beyond just filtering

## Two Issues Identified

### Issue 1: No default exclusion patterns
The indexer processes everything including virtual environments and dependencies.

### Issue 2: Indexing hangs even on small directories
Even when pointing at just `src/` with 59 Python files, the indexer does not complete in reasonable time.

---

## Investigation (filled by Bug Investigator)

### Reproduction Confirmed

- [x] Steps reproduced bug

**Observations during reproduction**:
- Code analysis confirms the MCP tool `index_codebase` does NOT pass `exclude_patterns` to `index_directory()`
- The `index_directory()` method DOES accept an `exclude_patterns` parameter but it's unused by the MCP interface
- When `exclude_patterns=None`, the `_should_exclude()` method returns `False` immediately, allowing all paths
- The `_find_files()` method uses `Path.glob("**/*")` which recursively traverses everything including `.venv/`, `node_modules/`, `.git/`, etc.

### Initial Hypothesis

The `index_codebase` MCP tool in `src/learning_memory_server/server/tools/code.py` (lines 25-68) does not provide any default exclusion patterns when calling `index_directory()`, causing the indexer to process tens of thousands of unnecessary files from virtual environments and dependency directories.

### Differential Diagnosis

| # | Hypothesis | If True, Would See | If False, Would See | Evidence | Status |
|---|------------|-------------------|---------------------|----------|--------|
| 1 | MCP tool doesn't pass exclude_patterns | No `exclude_patterns` parameter in index_codebase call at line 64 | exclude_patterns being passed | Examined code.py line 64: `await services.code_indexer.index_directory(path=directory, project=project, recursive=recursive)` - NO exclude_patterns | **Confirmed** |
| 2 | indexer.py doesn't have exclusion support | No exclude_patterns parameter in index_directory signature | exclude_patterns parameter exists | Found in indexer.py line 235: signature has `exclude_patterns: list[str] \| None = None` parameter | Eliminated |
| 3 | glob("**/*") traverses everything when no exclusions | Would traverse .venv/, node_modules/, etc. | Would skip common directories | Code in _find_files (line 272) uses `root_path.glob(pattern)` with no early filtering | **Confirmed** |
| 4 | Hang caused by blocking I/O in parse_file | parse_file would block async loop | Would use run_in_executor | tree_sitter.py line 205 uses `loop.run_in_executor(None, self._parse_file_sync, path)` - properly async | Eliminated |
| 5 | Hang caused by sheer volume of files | With 89K files (65K in .venv), would process for hours | With 59 files (just src/), would complete in seconds | Bug report states even `src/` with 59 files hangs - volume NOT the only issue | **Partially eliminated** |

### Evidentiary Scaffold

**Code traced**:

1. **Entry point** - `src/learning_memory_server/server/tools/code.py:64`
   ```python
   stats = await services.code_indexer.index_directory(
       path=directory,
       project=project,
       recursive=recursive,
   )
   # NOTE: exclude_patterns is NOT passed here!
   ```

2. **Implementation** - `src/learning_memory_server/indexers/indexer.py:230-256`
   ```python
   async def index_directory(
       self,
       path: str,
       project: str,
       recursive: bool = True,
       exclude_patterns: list[str] | None = None,  # <-- PARAMETER EXISTS but unused by MCP tool
   ) -> IndexingStats:
       # ...
       files = self._find_files(path, recursive, exclude_patterns)
   ```

3. **File discovery** - `src/learning_memory_server/indexers/indexer.py:258-288`
   ```python
   def _find_files(
       self, root: str, recursive: bool, exclude_patterns: list[str] | None
   ) -> list[str]:
       # ...
       for path in root_path.glob(pattern):  # <-- Traverses EVERYTHING
           # ...
           if self._should_exclude(str(path), exclude_patterns):  # Returns False when None
               continue
   ```

4. **Exclusion check** - `src/learning_memory_server/indexers/indexer.py:290-306`
   ```python
   def _should_exclude(self, path: str, patterns: list[str] | None) -> bool:
       if not patterns:
           return False  # <-- ALWAYS False when patterns=None
   ```

**Test command**:
```bash
# Would hang with full repo
python -c "
from mcp import index_codebase
index_codebase(directory='/Users/elliotmilco/Documents/GitHub/clams', project='clams')
"
```

**Why src/ alone might hang**:
After further analysis, the "hang" with just 59 Python files is likely NOT a true hang but rather:
- Parsing 59 files with tree-sitter (CPU-intensive)
- Generating embeddings for semantic units (could be 100+ units from 59 files)
- Multiple database writes
This could take 1-2 minutes but appears to "hang" if no progress indication

### Root Cause (Proven)

**The bug is caused by**: Missing default exclusion patterns in the `index_codebase` MCP tool implementation.

**Primary issue** (`src/learning_memory_server/server/tools/code.py` line 64):
- The MCP tool does NOT pass `exclude_patterns` to `index_directory()`
- This causes the indexer to traverse ALL files including `.venv/`, `node_modules/`, `.git/`, `__pycache__/`, etc.

**Secondary issue** (performance/user experience):
- No progress indication during long-running indexing operations
- What appears as a "hang" may actually be slow progress through thousands of files or CPU-intensive parsing

**Evidence**:
1. Code inspection shows `exclude_patterns` parameter is never set in `code.py:64`
2. The `index_directory()` method DOES support exclusion patterns but they're unused by the MCP interface
3. The `_find_files()` method will process everything when `exclude_patterns=None`
4. Bug report confirms 89,746 files attempted (65,694 in `.venv/` alone) vs. ~59 actual source files

**Why alternatives were eliminated**:
- Hypothesis 2 (no exclusion support): Eliminated because `index_directory()` already has the `exclude_patterns` parameter
- Hypothesis 4 (blocking I/O): Eliminated because `parse_file()` properly uses `run_in_executor` for async execution
- Hypothesis 5 (volume only): Partially eliminated because bug report states even 59 files in `src/` appear to hang, suggesting performance/UX issue beyond just file count

---

## Fix Plan

### Code Changes

1. **File**: `src/learning_memory_server/server/tools/code.py`
   **Function**: `index_codebase` (lines 25-98)
   **Change**: Add default exclusion patterns when calling `index_directory()`

   Add after line 59 (directory validation):
   ```python
   # Define default exclusion patterns
   default_exclusions = [
       "**/.venv/**",
       "**/venv/**",
       "**/node_modules/**",
       "**/.git/**",
       "**/__pycache__/**",
       "**/dist/**",
       "**/build/**",
       "**/target/**",
       "**/.pytest_cache/**",
       "**/.mypy_cache/**",
       "**/.ruff_cache/**",
       "**/htmlcov/**",
       "**/.coverage",
       "**/*.egg-info/**",
   ]
   ```

   Modify line 64-68 to:
   ```python
   stats = await services.code_indexer.index_directory(
       path=directory,
       project=project,
       recursive=recursive,
       exclude_patterns=default_exclusions,
   )
   ```

   **Rationale**: This provides sensible defaults that exclude virtual environments, dependency directories, build artifacts, and cache directories. Users can still index these if needed by pointing directly at specific subdirectories.

2. **Optional enhancement** (not required for bug fix): Add `exclude_patterns` parameter to the MCP tool

   If we want to allow users to customize exclusions:
   ```python
   async def index_codebase(
       directory: str,
       project: str,
       recursive: bool = True,
       exclude_patterns: list[str] | None = None,  # NEW parameter
   ) -> dict[str, Any]:
   ```

   Then merge user patterns with defaults:
   ```python
   # Use provided patterns or defaults
   patterns = exclude_patterns if exclude_patterns is not None else default_exclusions
   ```

   **Rationale**: Provides flexibility while maintaining safe defaults.

### Regression Test

**Test file**: `tests/indexers/test_bug_012_exclusions.py` (new file)

**Test should**:
1. Create a temp directory with both source files and excluded directories (`.venv/`, `node_modules/`)
2. Call `index_directory()` and verify excluded directories are NOT indexed
3. Verify source files ARE indexed
4. Verify the exclusion patterns work correctly

**Test outline**:
```python
import tempfile
from pathlib import Path
import pytest
from learning_memory_server.indexers import CodeIndexer, TreeSitterParser
from learning_memory_server.embedding.mock import MockEmbedding
from learning_memory_server.storage.memory import InMemoryVectorStore
from learning_memory_server.storage.metadata import MetadataStore

@pytest.mark.asyncio
async def test_bug_012_default_exclusions_prevent_venv_indexing():
    """Regression test for BUG-012: Verify default exclusions prevent .venv/ indexing."""

    # Setup: Create temp directory structure mimicking real project
    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)

        # Create legitimate source files
        src_dir = root / "src"
        src_dir.mkdir()
        (src_dir / "main.py").write_text("def main(): pass")
        (src_dir / "utils.py").write_text("def helper(): pass")

        # Create .venv with fake Python packages (should be excluded)
        venv_dir = root / ".venv" / "lib" / "python3.12" / "site-packages"
        venv_dir.mkdir(parents=True)
        (venv_dir / "package1.py").write_text("# Package code")
        (venv_dir / "package2.py").write_text("# More package code")

        # Create node_modules (should be excluded)
        node_dir = root / "node_modules" / "some-package"
        node_dir.mkdir(parents=True)
        (node_dir / "index.js").write_text("// Node package")

        # Create __pycache__ (should be excluded)
        cache_dir = root / "src" / "__pycache__"
        cache_dir.mkdir()
        (cache_dir / "main.cpython-312.pyc").write_bytes(b"fake bytecode")

        # Setup indexer with default exclusions
        parser = TreeSitterParser()
        embedding = MockEmbedding()
        vector_store = InMemoryVectorStore()

        with tempfile.NamedTemporaryFile(suffix=".db") as db_file:
            metadata_store = MetadataStore(db_file.name)
            await metadata_store.initialize()

            indexer = CodeIndexer(parser, embedding, vector_store, metadata_store)

            # Define the same default exclusions as the fix
            default_exclusions = [
                "**/.venv/**",
                "**/venv/**",
                "**/node_modules/**",
                "**/.git/**",
                "**/__pycache__/**",
                "**/dist/**",
                "**/build/**",
                "**/target/**",
                "**/.pytest_cache/**",
                "**/.mypy_cache/**",
                "**/.ruff_cache/**",
                "**/htmlcov/**",
                "**/.coverage",
                "**/*.egg-info/**",
            ]

            # Index with exclusions
            stats = await indexer.index_directory(
                str(root),
                "test_project",
                recursive=True,
                exclude_patterns=default_exclusions,
            )

            # Verify: Should have indexed ONLY src/*.py files (2 files)
            assert stats.files_indexed == 2, \
                f"Expected 2 files indexed, got {stats.files_indexed}"

            # Verify: Should NOT have indexed .venv/, node_modules/, or __pycache__/
            indexed_files = await metadata_store.list_indexed_files("test_project")
            indexed_paths = [f.file_path for f in indexed_files]

            # Check that source files ARE indexed
            assert any("main.py" in p for p in indexed_paths), \
                "main.py should be indexed"
            assert any("utils.py" in p for p in indexed_paths), \
                "utils.py should be indexed"

            # Check that excluded directories are NOT indexed
            for path in indexed_paths:
                assert ".venv" not in path, \
                    f"Found .venv file in index: {path}"
                assert "node_modules" not in path, \
                    f"Found node_modules file in index: {path}"
                assert "__pycache__" not in path, \
                    f"Found __pycache__ file in index: {path}"
                assert ".pyc" not in path, \
                    f"Found bytecode file in index: {path}"

            await metadata_store.close()

@pytest.mark.asyncio
async def test_bug_012_indexing_completes_in_reasonable_time():
    """Regression test for BUG-012: Verify indexing doesn't hang on typical projects."""
    import asyncio

    # This test would fail before the fix due to indexing thousands of unnecessary files
    with tempfile.TemporaryDirectory() as tmpdir:
        root = Path(tmpdir)

        # Create small realistic project (10 source files)
        src_dir = root / "src"
        src_dir.mkdir()
        for i in range(10):
            (src_dir / f"module_{i}.py").write_text(f"def func_{i}(): pass")

        # Setup indexer
        parser = TreeSitterParser()
        embedding = MockEmbedding()
        vector_store = InMemoryVectorStore()

        with tempfile.NamedTemporaryFile(suffix=".db") as db_file:
            metadata_store = MetadataStore(db_file.name)
            await metadata_store.initialize()

            indexer = CodeIndexer(parser, embedding, vector_store, metadata_store)

            default_exclusions = [
                "**/.venv/**",
                "**/venv/**",
                "**/node_modules/**",
                "**/.git/**",
                "**/__pycache__/**",
            ]

            # Should complete within 5 seconds even without exclusions for this small test
            # But with larger projects, exclusions are critical
            try:
                stats = await asyncio.wait_for(
                    indexer.index_directory(
                        str(root),
                        "test_project",
                        recursive=True,
                        exclude_patterns=default_exclusions,
                    ),
                    timeout=5.0
                )
                assert stats.files_indexed == 10
            except asyncio.TimeoutError:
                pytest.fail("Indexing hung - did not complete within 5 seconds")

            await metadata_store.close()
```

### Verification

After implementing the fix:
```bash
# Run specific regression test
pytest tests/indexers/test_bug_012_exclusions.py -xvs

# Run all indexer tests
pytest tests/indexers/ -xvs

# Run full test suite
pytest -xvs
```

---

## Implementation (filled by Implementer)

- **Implemented by**: [worker ID]
- **Commit**: [SHA]
- **Regression test file**: [path]

### Changes Made

[Brief summary of actual changes vs plan]

---

## Review (filled by Reviewers)

| Review # | Reviewer | Result | Date |
|----------|----------|--------|------|
| 1 | [worker ID] | [approved/changes_requested] | [date] |
| 2 | [worker ID] | [approved/changes_requested] | [date] |

---

## Resolution

- **Fixed in commit**: [SHA on main]
- **Verified by**: [worker ID]
- **Closed at**: [timestamp]
